{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import CIFAR100\n",
    "import numpy as np\n",
    "from resnet18 import ResNet18_NoFC, ProjectionHead, BasicBlock, count_parameters\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "2798880\n",
      "Epoch [1/100], Loss: 8.2444\n",
      "Epoch [2/100], Loss: 8.2046\n",
      "Epoch [3/100], Loss: 8.1249\n",
      "Epoch [4/100], Loss: 8.0682\n",
      "Epoch [5/100], Loss: 8.0829\n",
      "Epoch [6/100], Loss: 8.0600\n",
      "Epoch [7/100], Loss: 7.9920\n",
      "Epoch [8/100], Loss: 7.9826\n",
      "Epoch [9/100], Loss: 7.9687\n",
      "Epoch [10/100], Loss: 7.8877\n",
      "Epoch [11/100], Loss: 7.8565\n",
      "Epoch [12/100], Loss: 7.8409\n",
      "Epoch [13/100], Loss: 7.8273\n",
      "Epoch [14/100], Loss: 7.8308\n",
      "Epoch [15/100], Loss: 7.7679\n",
      "Epoch [16/100], Loss: 7.7329\n",
      "Epoch [17/100], Loss: 7.7735\n",
      "Epoch [18/100], Loss: 7.7261\n",
      "Epoch [19/100], Loss: 7.7096\n",
      "Epoch [20/100], Loss: 7.7342\n",
      "Epoch [21/100], Loss: 7.6978\n",
      "Epoch [22/100], Loss: 7.6557\n",
      "Epoch [23/100], Loss: 7.6638\n",
      "Epoch [24/100], Loss: 7.6612\n",
      "Epoch [25/100], Loss: 7.5904\n",
      "Epoch [26/100], Loss: 7.6269\n",
      "Epoch [27/100], Loss: 7.5931\n",
      "Epoch [28/100], Loss: 7.5260\n",
      "Epoch [29/100], Loss: 7.5452\n",
      "Epoch [30/100], Loss: 7.5299\n",
      "Epoch [31/100], Loss: 7.5005\n",
      "Epoch [32/100], Loss: 7.4932\n",
      "Epoch [33/100], Loss: 7.4039\n",
      "Epoch [34/100], Loss: 7.4495\n",
      "Epoch [35/100], Loss: 7.4541\n",
      "Epoch [36/100], Loss: 7.4123\n",
      "Epoch [37/100], Loss: 7.4235\n",
      "Epoch [38/100], Loss: 7.4536\n",
      "Epoch [39/100], Loss: 7.3677\n",
      "Epoch [40/100], Loss: 7.4211\n",
      "Epoch [41/100], Loss: 7.3481\n",
      "Epoch [42/100], Loss: 7.4080\n",
      "Epoch [43/100], Loss: 7.3245\n",
      "Epoch [44/100], Loss: 7.3964\n",
      "Epoch [45/100], Loss: 7.3127\n",
      "Epoch [46/100], Loss: 7.2369\n",
      "Epoch [47/100], Loss: 7.2951\n",
      "Epoch [48/100], Loss: 7.3150\n",
      "Epoch [49/100], Loss: 7.2891\n",
      "Epoch [50/100], Loss: 7.3123\n",
      "Epoch [51/100], Loss: 7.2993\n",
      "Epoch [52/100], Loss: 7.2478\n",
      "Epoch [53/100], Loss: 7.2965\n",
      "Epoch [54/100], Loss: 7.2136\n",
      "Epoch [55/100], Loss: 7.2431\n",
      "Epoch [56/100], Loss: 7.2478\n",
      "Epoch [57/100], Loss: 7.2546\n",
      "Epoch [58/100], Loss: 7.2352\n",
      "Epoch [59/100], Loss: 7.2112\n",
      "Epoch [60/100], Loss: 7.2149\n",
      "Epoch [61/100], Loss: 7.1928\n",
      "Epoch [62/100], Loss: 7.1995\n",
      "Epoch [63/100], Loss: 7.1508\n",
      "Epoch [64/100], Loss: 7.1755\n",
      "Epoch [65/100], Loss: 7.1698\n",
      "Epoch [66/100], Loss: 7.2081\n",
      "Epoch [67/100], Loss: 7.2219\n",
      "Epoch [68/100], Loss: 7.2089\n",
      "Epoch [69/100], Loss: 7.1688\n",
      "Epoch [70/100], Loss: 7.0846\n",
      "Epoch [71/100], Loss: 7.1064\n",
      "Epoch [72/100], Loss: 7.1681\n",
      "Epoch [73/100], Loss: 7.0949\n",
      "Epoch [74/100], Loss: 7.1418\n",
      "Epoch [75/100], Loss: 7.2206\n",
      "Epoch [76/100], Loss: 7.1738\n",
      "Epoch [77/100], Loss: 7.1255\n",
      "Epoch [78/100], Loss: 7.1153\n",
      "Epoch [79/100], Loss: 7.0917\n",
      "Epoch [80/100], Loss: 7.1313\n",
      "Epoch [81/100], Loss: 7.1501\n",
      "Epoch [82/100], Loss: 7.1209\n",
      "Epoch [83/100], Loss: 7.0504\n",
      "Epoch [84/100], Loss: 7.1135\n",
      "Epoch [85/100], Loss: 7.1300\n",
      "Epoch [86/100], Loss: 7.0885\n",
      "Epoch [87/100], Loss: 7.0642\n",
      "Epoch [88/100], Loss: 7.1239\n",
      "Epoch [89/100], Loss: 7.0485\n",
      "Epoch [90/100], Loss: 7.0768\n",
      "Epoch [91/100], Loss: 7.0422\n",
      "Epoch [92/100], Loss: 7.0316\n",
      "Epoch [93/100], Loss: 6.9896\n",
      "Epoch [94/100], Loss: 7.0730\n",
      "Epoch [95/100], Loss: 7.0749\n",
      "Epoch [96/100], Loss: 7.0263\n",
      "Epoch [97/100], Loss: 7.0338\n",
      "Epoch [98/100], Loss: 7.0174\n",
      "Epoch [99/100], Loss: 7.0060\n",
      "Epoch [100/100], Loss: 6.9803\n"
     ]
    }
   ],
   "source": [
    "class SimCLRTransform:\n",
    "    def __init__(self, size):\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(size=size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomApply([\n",
    "                transforms.ColorJitter(0.8, 0.8, 0.8, 0.2)\n",
    "            ], p=0.8),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "        ])\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.transform(x), self.transform(x)\n",
    "\n",
    "\n",
    "class CIFAR100SimCLR(Dataset):\n",
    "    def __init__(self, root='./data', train=True, transform=None):\n",
    "        self.dataset = CIFAR100(root=root, train=train, download=True, transform=transform)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, _ = self.dataset[idx]\n",
    "        return img\n",
    "\n",
    "simclr_transform = SimCLRTransform(5) # cifar \n",
    "train_dataset = CIFAR100SimCLR(train=True, transform=simclr_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4000, shuffle=True, num_workers=0)\n",
    "\n",
    "\n",
    "    \n",
    "def nt_xent_loss(z_i, z_j, temperature):\n",
    "    \"\"\"\n",
    "    Calculates the NT-Xent loss.\n",
    "    z_i, z_j are the representations of two augmentations of the same image, \n",
    "    and should be normalized.\n",
    "    \"\"\"\n",
    "    batch_size = z_i.size(0)\n",
    "\n",
    "    z = torch.cat((z_i, z_j), dim=0)\n",
    "    sim_matrix = torch.exp(torch.mm(z, z.T) / temperature)\n",
    "\n",
    "    mask = torch.eye(batch_size, dtype=torch.bool).to(z.device)\n",
    "    mask = mask.repeat(2, 2)\n",
    "    sim_matrix = sim_matrix.masked_select(~mask).view(2 * batch_size, -1)\n",
    "\n",
    "    positives = torch.exp(torch.sum(z_i * z_j, dim=-1) / temperature).repeat(2)\n",
    "    negatives = sim_matrix.sum(dim=-1)\n",
    "\n",
    "    loss = -torch.log(positives / negatives).mean()\n",
    "    return loss\n",
    "\n",
    "num_filters = [32, 32, 64, 128, 256]  # Example filter numbers for each layer\n",
    "model = ResNet18_NoFC(BasicBlock, [2, 2, 2, 2], num_filters).to(device)\n",
    "projection_head = ProjectionHead(input_dim=num_filters[-1], hidden_dim=512, output_dim=128).to(device)\n",
    "\n",
    "print(count_parameters(model))\n",
    "\n",
    "def train(train_loader, model, projection_head, optimizer, temperature=0.15, epochs=100):\n",
    "    for epoch in range(epochs):\n",
    "        for (images1, images2) in train_loader:\n",
    "            # Concatenate the images from the two augmentations\n",
    "            images = torch.cat([images1, images2], dim=0)\n",
    "            images = images.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            features = model(images)\n",
    "            projections = projection_head(features)\n",
    "            projections = F.normalize(projections, dim=1)\n",
    "\n",
    "            loss = nt_xent_loss(projections[:len(images)//2], projections[len(images)//2:], temperature)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print loss (or log it)\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "optimizer = torch.optim.AdamW(list(model.parameters()) + list(projection_head.parameters()), lr=1e-2, weight_decay=1e-4)\n",
    "train(train_loader, model, projection_head, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.cpu(),\"resnet18_simclr_cifar100_bs4000.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Random seed set as 0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "num_parameters: 11176512\n",
      "Epoch [1/100], Train Loss: 6.2897, Val Loss: 8.9863\n",
      "Epoch [2/100], Train Loss: 6.0888, Val Loss: 8.8555\n",
      "Epoch [3/100], Train Loss: 6.0500, Val Loss: 8.8296\n",
      "Epoch [4/100], Train Loss: 6.0948, Val Loss: 8.8159\n",
      "Epoch [5/100], Train Loss: 5.8345, Val Loss: 8.6807\n",
      "Epoch [6/100], Train Loss: 6.0102, Val Loss: 8.6974\n",
      "Epoch [7/100], Train Loss: 5.7252, Val Loss: 8.5794\n",
      "Epoch [8/100], Train Loss: 5.6922, Val Loss: 8.5957\n",
      "Epoch [9/100], Train Loss: 5.7884, Val Loss: 8.5025\n",
      "Epoch [10/100], Train Loss: 5.6733, Val Loss: 8.4335\n",
      "Epoch [11/100], Train Loss: 5.5639, Val Loss: 8.4713\n",
      "Epoch [12/100], Train Loss: 5.6091, Val Loss: 8.5019\n",
      "Epoch [13/100], Train Loss: 5.6258, Val Loss: 8.5079\n",
      "Epoch [14/100], Train Loss: 5.5456, Val Loss: 8.3049\n",
      "Epoch [15/100], Train Loss: 5.5884, Val Loss: 8.3944\n",
      "Epoch [16/100], Train Loss: 5.4775, Val Loss: 8.3046\n",
      "Epoch [17/100], Train Loss: 5.5451, Val Loss: 8.4410\n",
      "Epoch [18/100], Train Loss: 5.5026, Val Loss: 8.3731\n",
      "Epoch [19/100], Train Loss: 5.4182, Val Loss: 8.3812\n",
      "Epoch [20/100], Train Loss: 5.4464, Val Loss: 8.2576\n",
      "Epoch [21/100], Train Loss: 5.5808, Val Loss: 8.3657\n",
      "Epoch [22/100], Train Loss: 5.4448, Val Loss: 8.3082\n",
      "Epoch [23/100], Train Loss: 5.4606, Val Loss: 8.2841\n",
      "Epoch [24/100], Train Loss: 5.4132, Val Loss: 8.1814\n",
      "Epoch [25/100], Train Loss: 5.4196, Val Loss: 8.2303\n",
      "Epoch [26/100], Train Loss: 5.3009, Val Loss: 8.2222\n",
      "Epoch [27/100], Train Loss: 5.3286, Val Loss: 8.3265\n",
      "Epoch [28/100], Train Loss: 5.4075, Val Loss: 8.2340\n",
      "Epoch [29/100], Train Loss: 5.4288, Val Loss: 8.2075\n",
      "Epoch [30/100], Train Loss: 5.2715, Val Loss: 8.1161\n",
      "Epoch [31/100], Train Loss: 5.3848, Val Loss: 8.1256\n",
      "Epoch [32/100], Train Loss: 5.3949, Val Loss: 8.0615\n",
      "Epoch [33/100], Train Loss: 5.3267, Val Loss: 8.1825\n",
      "Epoch [34/100], Train Loss: 5.2463, Val Loss: 8.0258\n",
      "Epoch [35/100], Train Loss: 5.3378, Val Loss: 8.1388\n",
      "Epoch [36/100], Train Loss: 5.1445, Val Loss: 8.1720\n",
      "Epoch [37/100], Train Loss: 5.3065, Val Loss: 8.0531\n",
      "Epoch [38/100], Train Loss: 5.1551, Val Loss: 8.1431\n",
      "Epoch [39/100], Train Loss: 5.1558, Val Loss: 8.0085\n",
      "Epoch [40/100], Train Loss: 5.1285, Val Loss: 8.0663\n",
      "Epoch [41/100], Train Loss: 5.2345, Val Loss: 7.9946\n",
      "Epoch [42/100], Train Loss: 5.2230, Val Loss: 8.0350\n",
      "Epoch [43/100], Train Loss: 5.1527, Val Loss: 8.0130\n",
      "Epoch [44/100], Train Loss: 5.1132, Val Loss: 7.9524\n",
      "Epoch [45/100], Train Loss: 5.1122, Val Loss: 7.9271\n",
      "Epoch [46/100], Train Loss: 5.1219, Val Loss: 8.1394\n",
      "Epoch [47/100], Train Loss: 5.1396, Val Loss: 7.9431\n",
      "Epoch [48/100], Train Loss: 5.1421, Val Loss: 8.1518\n",
      "Epoch [49/100], Train Loss: 5.0101, Val Loss: 8.1869\n",
      "Epoch [50/100], Train Loss: 5.0790, Val Loss: 8.1182\n",
      "Epoch [51/100], Train Loss: 4.9767, Val Loss: 7.9866\n",
      "Epoch [52/100], Train Loss: 4.9299, Val Loss: 7.8604\n",
      "Epoch [53/100], Train Loss: 5.1038, Val Loss: 7.8957\n",
      "Epoch [54/100], Train Loss: 4.8711, Val Loss: 7.7729\n",
      "Epoch [55/100], Train Loss: 4.8644, Val Loss: 7.8641\n",
      "Epoch [56/100], Train Loss: 4.9038, Val Loss: 7.8021\n",
      "Epoch [57/100], Train Loss: 4.9636, Val Loss: 7.7952\n",
      "Epoch [58/100], Train Loss: 4.9097, Val Loss: 7.8403\n",
      "Epoch [59/100], Train Loss: 4.8668, Val Loss: 7.8593\n",
      "Epoch [60/100], Train Loss: 4.8434, Val Loss: 7.7182\n",
      "Epoch [61/100], Train Loss: 4.8786, Val Loss: 7.7497\n",
      "Epoch [62/100], Train Loss: 5.1027, Val Loss: 7.8690\n",
      "Epoch [63/100], Train Loss: 4.9855, Val Loss: 7.7326\n",
      "Epoch [64/100], Train Loss: 4.9531, Val Loss: 7.8574\n",
      "Epoch [65/100], Train Loss: 4.8879, Val Loss: 7.9448\n",
      "Epoch [66/100], Train Loss: 4.8531, Val Loss: 7.6989\n",
      "Epoch [67/100], Train Loss: 4.8402, Val Loss: 7.6914\n",
      "Epoch [68/100], Train Loss: 4.7590, Val Loss: 7.7759\n",
      "Epoch [69/100], Train Loss: 4.8210, Val Loss: 7.7217\n",
      "Epoch [70/100], Train Loss: 4.9267, Val Loss: 7.6487\n",
      "Epoch [71/100], Train Loss: 4.8871, Val Loss: 7.6184\n",
      "Epoch [72/100], Train Loss: 4.7696, Val Loss: 7.7674\n",
      "Epoch [73/100], Train Loss: 4.8969, Val Loss: 7.7007\n",
      "Epoch [74/100], Train Loss: 4.7445, Val Loss: 7.6733\n",
      "Epoch [75/100], Train Loss: 4.9410, Val Loss: 7.6181\n",
      "Epoch [76/100], Train Loss: 4.8533, Val Loss: 7.6486\n",
      "Epoch [77/100], Train Loss: 4.6525, Val Loss: 7.7075\n",
      "Epoch [78/100], Train Loss: 4.6587, Val Loss: 7.6153\n",
      "Epoch [79/100], Train Loss: 4.8280, Val Loss: 7.7170\n",
      "Epoch [80/100], Train Loss: 4.5068, Val Loss: 7.6401\n",
      "Epoch [81/100], Train Loss: 4.8673, Val Loss: 7.6575\n",
      "Epoch [82/100], Train Loss: 4.7931, Val Loss: 7.5398\n",
      "Epoch [83/100], Train Loss: 4.7668, Val Loss: 7.6426\n",
      "Epoch [84/100], Train Loss: 4.8242, Val Loss: 7.6500\n",
      "Epoch [85/100], Train Loss: 4.6751, Val Loss: 7.6185\n",
      "Epoch [86/100], Train Loss: 4.7666, Val Loss: 7.5582\n",
      "Epoch [87/100], Train Loss: 4.7917, Val Loss: 7.5162\n",
      "Epoch [88/100], Train Loss: 4.6092, Val Loss: 7.6345\n",
      "Epoch [89/100], Train Loss: 4.6168, Val Loss: 7.5325\n",
      "Epoch [90/100], Train Loss: 4.3806, Val Loss: 7.6170\n",
      "Epoch [91/100], Train Loss: 4.7340, Val Loss: 7.5812\n",
      "Epoch [92/100], Train Loss: 4.6531, Val Loss: 7.6125\n",
      "Epoch [93/100], Train Loss: 4.7215, Val Loss: 7.5276\n",
      "Epoch [94/100], Train Loss: 4.7863, Val Loss: 7.5231\n",
      "Epoch [95/100], Train Loss: 4.7086, Val Loss: 7.5585\n",
      "Epoch [96/100], Train Loss: 4.7116, Val Loss: 7.6490\n",
      "Epoch [97/100], Train Loss: 4.6025, Val Loss: 7.5936\n",
      "Epoch [98/100], Train Loss: 4.7428, Val Loss: 7.5692\n",
      "Epoch [99/100], Train Loss: 4.3712, Val Loss: 7.2996\n",
      "Epoch [100/100], Train Loss: 4.5889, Val Loss: 7.3043\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import CIFAR100\n",
    "import numpy as np\n",
    "from resnet18 import ResNet18_NoFC, ProjectionHead, BasicBlock, count_parameters\n",
    "import os, random, itertools\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "\n",
    "\n",
    "class SimCLRTransform:\n",
    "    def __init__(self, size):\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(size=size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomApply([\n",
    "                transforms.ColorJitter(0.8, 0.8, 0.8, 0.2)\n",
    "            ], p=0.8),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "        ])\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.transform(x), self.transform(x)\n",
    "\n",
    "\n",
    "class CIFAR100SimCLR(Dataset):\n",
    "    def __init__(self, root='./data', train=True, transform=None):\n",
    "        self.dataset = CIFAR100(root=root, train=train, download=True, transform=transform)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, _ = self.dataset[idx]\n",
    "        return img\n",
    "    \n",
    "def nt_xent_loss(z_i, z_j, temperature):\n",
    "    \"\"\"\n",
    "    Calculates the NT-Xent loss.\n",
    "    z_i, z_j are the representations of two augmentations of the same image, \n",
    "    and should be normalized.\n",
    "    \"\"\"\n",
    "    batch_size = z_i.size(0)\n",
    "\n",
    "    z = torch.cat((z_i, z_j), dim=0)\n",
    "    sim_matrix = torch.exp(torch.mm(z, z.T) / temperature)\n",
    "\n",
    "    mask = torch.eye(batch_size, dtype=torch.bool).to(z.device)\n",
    "    mask = mask.repeat(2, 2)\n",
    "    sim_matrix = sim_matrix.masked_select(~mask).view(2 * batch_size, -1)\n",
    "\n",
    "    positives = torch.exp(torch.sum(z_i * z_j, dim=-1) / temperature).repeat(2)\n",
    "    negatives = sim_matrix.sum(dim=-1)\n",
    "\n",
    "    loss = -torch.log(positives / negatives).mean()\n",
    "    return loss\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "filter_list = np.array([64,64,128,256,512])\n",
    "\n",
    "# divisor = list(np.geomspace(1, 32, 40))\n",
    "\n",
    "# seed_list = [0,1,2]\n",
    "\n",
    "# para_comb = list(itertools.product(seed_list, divisor))\n",
    "\n",
    "(seed, d) = (0, 1)\n",
    "\n",
    "num_filters = (filter_list / d).astype(int)  # [32, 32, 64, 128, 256]  filter numbers for each layer\n",
    "set_seed(seed)\n",
    "\n",
    "simclr_transform = SimCLRTransform(5) # cifar \n",
    "train_dataset = CIFAR100SimCLR(train=True, transform=simclr_transform)\n",
    "val_dataset =  CIFAR100SimCLR(train=False, transform=simclr_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True, num_workers=0)\n",
    "val_loader =  DataLoader(val_dataset, batch_size=5000, shuffle=False, num_workers=0)\n",
    "\n",
    "num_epochs = 100\n",
    "model = ResNet18_NoFC(BasicBlock, [2, 2, 2, 2], num_filters).to(device)\n",
    "projection_head = ProjectionHead(input_dim=num_filters[-1], hidden_dim=512, output_dim=128).to(device)\n",
    "\n",
    "print(\"num_parameters:\",count_parameters(model))\n",
    "\n",
    "def train(train_loader, model, projection_head, optimizer, scheduler, temperature=0.15, epochs=num_epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for (images1, images2) in train_loader:\n",
    "            model.train()\n",
    "            # Concatenate the images from the two augmentations\n",
    "            images = torch.cat([images1, images2], dim=0)\n",
    "            images = images.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            features = model(images)\n",
    "            projections = projection_head(features)\n",
    "            projections = F.normalize(projections, dim=1)\n",
    "\n",
    "            loss = nt_xent_loss(projections[:len(images)//2], projections[len(images)//2:], temperature)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        # Validation\n",
    "        val_loss_list = []\n",
    "        for (images1, images2) in val_loader:\n",
    "            model.eval()\n",
    "            # Concatenate the images from the two augmentations\n",
    "            images = torch.cat([images1, images2], dim=0)\n",
    "            images = images.to(device)\n",
    "\n",
    "            features = model(images)\n",
    "            projections = projection_head(features)\n",
    "            projections = F.normalize(projections, dim=1)\n",
    "\n",
    "            val_loss = nt_xent_loss(projections[:len(images)//2], projections[len(images)//2:], temperature)\n",
    "            val_loss_list.append(val_loss.item())\n",
    "        scheduler.step(np.mean(val_loss_list))\n",
    "            \n",
    "            # Print loss (or log it)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n",
    "        \n",
    "    return model\n",
    "\n",
    "optimizer = torch.optim.AdamW(list(model.parameters()) + list(projection_head.parameters()), lr=1e-2, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "model = train(train_loader, model, projection_head, optimizer, scheduler)\n",
    "\n",
    "torch.save(model,f\"resnet18_simclr_cifar100_parameters{count_parameters(model)}_seed{seed}_bs512.pt\")\n",
    "\n",
    "# torch.save(model,f\"~/scratch/models/resnet18_simclr_cifar100_parameters{count_parameters(model)}_seed{seed}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24548\\4212379655.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mval_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'val_loss' is not defined"
     ]
    }
   ],
   "source": [
    "val_loss\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scaling_law_train_ker",
   "language": "python",
   "name": "scaling_law_train_ker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
