{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"resnet18_simclr_cifar100_centered.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Random seed set as 0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "23231296\n",
      "Epoch [1/10], Train Loss: 7.4259, Val Loss: 9.1901\n",
      "Epoch [2/10], Train Loss: 7.3744, Val Loss: 9.1315\n",
      "Epoch [3/10], Train Loss: 7.2775, Val Loss: 9.1407\n",
      "Epoch [4/10], Train Loss: 7.3240, Val Loss: 9.0635\n",
      "Epoch [5/10], Train Loss: 7.2312, Val Loss: 9.0311\n",
      "Epoch [6/10], Train Loss: 7.2745, Val Loss: 9.0366\n",
      "Epoch [7/10], Train Loss: 7.2476, Val Loss: 9.0227\n",
      "Epoch [8/10], Train Loss: 7.3028, Val Loss: 9.0539\n",
      "Epoch [9/10], Train Loss: 7.2232, Val Loss: 9.0059\n",
      "Epoch [10/10], Train Loss: 7.2513, Val Loss: 9.0352\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import CIFAR100\n",
    "import numpy as np\n",
    "from alexnet_cifar import *\n",
    "import os, random\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "\n",
    "\n",
    "class SimCLRTransform:\n",
    "    def __init__(self, size):\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(size=size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomApply([\n",
    "                transforms.ColorJitter(0.8, 0.8, 0.8, 0.2)\n",
    "            ], p=0.8),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "        ])\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.transform(x), self.transform(x)\n",
    "\n",
    "\n",
    "class CIFAR100SimCLR(Dataset):\n",
    "    def __init__(self, root='./data', train=True, transform=None):\n",
    "        self.dataset = CIFAR100(root=root, train=train, download=True, transform=transform)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, _ = self.dataset[idx]\n",
    "        return img\n",
    "    \n",
    "def nt_xent_loss(z_i, z_j, temperature):\n",
    "    \"\"\"\n",
    "    Calculates the NT-Xent loss.\n",
    "    z_i, z_j are the representations of two augmentations of the same image, \n",
    "    and should be normalized.\n",
    "    \"\"\"\n",
    "    batch_size = z_i.size(0)\n",
    "\n",
    "    z = torch.cat((z_i, z_j), dim=0)\n",
    "    sim_matrix = torch.exp(torch.mm(z, z.T) / temperature)\n",
    "\n",
    "    mask = torch.eye(batch_size, dtype=torch.bool).to(z.device)\n",
    "    mask = mask.repeat(2, 2)\n",
    "    sim_matrix = sim_matrix.masked_select(~mask).view(2 * batch_size, -1)\n",
    "\n",
    "    positives = torch.exp(torch.sum(z_i * z_j, dim=-1) / temperature).repeat(2)\n",
    "    negatives = sim_matrix.sum(dim=-1)\n",
    "\n",
    "    loss = -torch.log(positives / negatives).mean()\n",
    "    return loss\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "set_seed(0)\n",
    "\n",
    "simclr_transform = SimCLRTransform(32) # cifar \n",
    "train_dataset = CIFAR100SimCLR(train=True, transform=simclr_transform)\n",
    "val_dataset =  CIFAR100SimCLR(train=False, transform=simclr_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024*4, shuffle=True, num_workers=0)\n",
    "val_loader =  DataLoader(val_dataset, batch_size=5000, shuffle=False, num_workers=0)\n",
    "\n",
    "num_filters = [64, 192, 384, 256, 256, 4096, 4096]  # Example filter numbers for each layer\n",
    "model = AlexNet_CIFAR_NoFC(num_filters).to(device)\n",
    "projection_head = ProjectionHead(input_dim=num_filters[-1], hidden_dim=512, output_dim=128).to(device)\n",
    "\n",
    "print(count_parameters(model))\n",
    "\n",
    "def train(train_loader, model, projection_head, optimizer, scheduler, temperature=0.15, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        for (images1, images2) in train_loader:\n",
    "            model.train()\n",
    "            # Concatenate the images from the two augmentations\n",
    "            images = torch.cat([images1, images2], dim=0)\n",
    "            images = images.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            features = model(images)\n",
    "            projections = projection_head(features)\n",
    "            projections = F.normalize(projections, dim=1)\n",
    "\n",
    "            loss = nt_xent_loss(projections[:len(images)//2], projections[len(images)//2:], temperature)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        # Validation\n",
    "        val_loss_list = []\n",
    "        for (images1, images2) in val_loader:\n",
    "            model.eval()\n",
    "            # Concatenate the images from the two augmentations\n",
    "            images = torch.cat([images1, images2], dim=0)\n",
    "            images = images.to(device)\n",
    "\n",
    "            features = model(images)\n",
    "            projections = projection_head(features)\n",
    "            projections = F.normalize(projections, dim=1)\n",
    "\n",
    "            val_loss = nt_xent_loss(projections[:len(images)//2], projections[len(images)//2:], temperature)\n",
    "            val_loss_list.append(val_loss.item())\n",
    "        scheduler.step(np.mean(val_loss_list))\n",
    "            \n",
    "            # Print loss (or log it)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {loss.item():.4f}, Val Loss: {np.mean(val_loss_list):.4f}')\n",
    "\n",
    "optimizer = torch.optim.AdamW(list(model.parameters()) + list(projection_head.parameters()), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "train(train_loader, model, projection_head, optimizer, scheduler)\n",
    "\n",
    "# torch.save(model,\"resnet18_simclr_cifar100.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  64  192  384  256  256 4096 4096]\n",
      "num parameters: 23231296\n",
      "[  58  175  351  234  234 3747 3747]\n",
      "num parameters: 19433498\n",
      "[  53  160  321  214  214 3429 3429]\n",
      "num parameters: 16271486\n",
      "[  49  147  294  196  196 3137 3137]\n",
      "num parameters: 13626805\n",
      "[  44  134  269  179  179 2870 2870]\n",
      "num parameters: 11398759\n",
      "[  41  123  246  164  164 2626 2626]\n",
      "num parameters: 9548498\n",
      "[  37  112  225  150  150 2403 2403]\n",
      "num parameters: 7993034\n",
      "[  34  103  206  137  137 2198 2198]\n",
      "num parameters: 6687038\n",
      "[  31   94  188  125  125 2011 2011]\n",
      "num parameters: 5592442\n",
      "[  28   86  172  115  115 1840 1840]\n",
      "num parameters: 4688797\n",
      "[  26   78  157  105  105 1684 1684]\n",
      "num parameters: 3923733\n",
      "[  24   72  144   96   96 1541 1541]\n",
      "num parameters: 3286811\n",
      "[  22   66  132   88   88 1410 1410]\n",
      "num parameters: 2753946\n",
      "[  20   60  120   80   80 1290 1290]\n",
      "num parameters: 2299980\n",
      "[  18   55  110   73   73 1180 1180]\n",
      "num parameters: 1923726\n",
      "[  16   50  101   67   67 1080 1080]\n",
      "num parameters: 1612687\n",
      "[ 15  46  92  61  61 988 988]\n",
      "num parameters: 1348167\n",
      "[ 14  42  84  56  56 904 904]\n",
      "num parameters: 1129754\n",
      "[ 12  38  77  51  51 827 827]\n",
      "num parameters: 944034\n",
      "[ 11  35  70  47  47 756 756]\n",
      "num parameters: 790689\n",
      "[ 10  32  64  43  43 692 692]\n",
      "num parameters: 662455\n",
      "[  9  29  59  39  39 633 633]\n",
      "num parameters: 553267\n",
      "[  9  27  54  36  36 579 579]\n",
      "num parameters: 464649\n",
      "[  8  24  49  33  33 530 530]\n",
      "num parameters: 388949\n",
      "[  7  22  45  30  30 485 485]\n",
      "num parameters: 325264\n",
      "[  6  20  41  27  27 444 444]\n",
      "num parameters: 271243\n",
      "[  6  19  38  25  25 406 406]\n",
      "num parameters: 228222\n",
      "[  5  17  34  23  23 371 371]\n",
      "num parameters: 190518\n",
      "[  5  15  31  21  21 340 340]\n",
      "num parameters: 159756\n",
      "[  4  14  29  19  19 311 311]\n",
      "num parameters: 133538\n",
      "[  4  13  26  17  17 284 284]\n",
      "num parameters: 110810\n",
      "[  4  12  24  16  16 260 260]\n",
      "num parameters: 93724\n",
      "[  3  11  22  14  14 238 238]\n",
      "num parameters: 77604\n",
      "[  3  10  20  13  13 218 218]\n",
      "num parameters: 65367\n",
      "[  3   9  18  12  12 199 199]\n",
      "num parameters: 54627\n",
      "[  2   8  17  11  11 182 182]\n",
      "num parameters: 45739\n",
      "[  2   7  15  10  10 167 167]\n",
      "num parameters: 38322\n",
      "[  2   7  14   9   9 152 152]\n",
      "num parameters: 31846\n",
      "[  2   6  13   8   8 139 139]\n",
      "num parameters: 26460\n",
      "[  2   6  12   8   8 128 128]\n",
      "num parameters: 23022\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import CIFAR100\n",
    "import numpy as np\n",
    "from alexnet_cifar import *\n",
    "import os, random\n",
    "\n",
    "filter_list = np.array([64, 192, 384, 256, 256, 4096, 4096])\n",
    "for i in list(np.geomspace(1, 32, 40)):\n",
    "    num_filters = (filter_list / i).astype(int)\n",
    "    print(num_filters)\n",
    "    model = AlexNet_CIFAR_NoFC(num_filters)\n",
    "    \n",
    "    print(\"num parameters:\", count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 64  64 128 256 512]\n",
      "num parameters: 11176512\n",
      "[ 58  58 117 234 468]\n",
      "num parameters: 9336823\n",
      "[ 53  53 107 214 428]\n",
      "num parameters: 7810128\n",
      "[ 49  49  98 196 392]\n",
      "num parameters: 6554877\n",
      "[ 44  44  89 179 358]\n",
      "num parameters: 5461556\n",
      "[ 41  41  82 164 328]\n",
      "num parameters: 4591221\n",
      "[ 37  37  75 150 300]\n",
      "num parameters: 3839968\n",
      "[ 34  34  68 137 274]\n",
      "num parameters: 3202067\n",
      "[ 31  31  62 125 251]\n",
      "num parameters: 2681003\n",
      "[ 28  28  57 115 230]\n",
      "num parameters: 2255748\n",
      "[ 26  26  52 105 210]\n",
      "num parameters: 1882091\n",
      "[ 24  24  48  96 192]\n",
      "num parameters: 1576152\n",
      "[ 22  22  44  88 176]\n",
      "num parameters: 1324950\n",
      "[ 20  20  40  80 161]\n",
      "num parameters: 1105017\n",
      "[ 18  18  36  73 147]\n",
      "num parameters: 919438\n",
      "[ 16  16  33  67 135]\n",
      "num parameters: 774599\n",
      "[ 15  15  30  61 123]\n",
      "num parameters: 643675\n",
      "[ 14  14  28  56 113]\n",
      "num parameters: 544707\n",
      "[ 12  12  25  51 103]\n",
      "num parameters: 450683\n",
      "[11 11 23 47 94]\n",
      "num parameters: 377741\n",
      "[10 10 21 43 86]\n",
      "num parameters: 316302\n",
      "[ 9  9 19 39 79]\n",
      "num parameters: 264950\n",
      "[ 9  9 18 36 72]\n",
      "num parameters: 223317\n",
      "[ 8  8 16 33 66]\n",
      "num parameters: 186977\n",
      "[ 7  7 15 30 60]\n",
      "num parameters: 155038\n",
      "[ 6  6 13 27 55]\n",
      "num parameters: 128249\n",
      "[ 6  6 12 25 50]\n",
      "num parameters: 107591\n",
      "[ 5  5 11 23 46]\n",
      "num parameters: 90827\n",
      "[ 5  5 10 21 42]\n",
      "num parameters: 76070\n",
      "[ 4  4  9 19 38]\n",
      "num parameters: 62076\n",
      "[ 4  4  8 17 35]\n",
      "num parameters: 52040\n",
      "[ 4  4  8 16 32]\n",
      "num parameters: 44772\n",
      "[ 3  3  7 14 29]\n",
      "num parameters: 35867\n",
      "[ 3  3  6 13 27]\n",
      "num parameters: 30943\n",
      "[ 3  3  6 12 24]\n",
      "num parameters: 25407\n",
      "[ 2  2  5 11 22]\n",
      "num parameters: 20918\n",
      "[ 2  2  5 10 20]\n",
      "num parameters: 17583\n",
      "[ 2  2  4  9 19]\n",
      "num parameters: 15294\n",
      "[ 2  2  4  8 17]\n",
      "num parameters: 12471\n",
      "[ 2  2  4  8 16]\n",
      "num parameters: 11490\n"
     ]
    }
   ],
   "source": [
    "filter_list = np.array([64,64,128,256,512])\n",
    "\n",
    "for i in list(np.geomspace(1, 32, 40)):\n",
    "    num_filters = (filter_list / i).astype(int)\n",
    "    print(num_filters)\n",
    "    model = ResNet18_NoFC(BasicBlock, [2, 2, 2, 2], num_filters)\n",
    "    print(\"num parameters:\", count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=0\n",
    "torch.save(model,f\"/home/mila/p/pingsheng.li/scratch/models/resnet18_simclr_cifar100_parameters{count_parameters(model)}_seed{seed}.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scaling_law_20231126",
   "language": "python",
   "name": "scaling_law_20231126"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
